#!/usr/bin/env python3
"""
Script d'entraÃ®nement offline pour le modÃ¨le de trading Forex.
EntraÃ®ne une rÃ©gression logistique et exporte les poids dans un fichier JSON.

Usage:
    python train_model.py <path_to_csv> [path_to_csv2] [path_to_csv3] ...
    python train_model.py data/currencies/*.csv
    python train_model.py data/currencies/gbp_eur.csv data/currencies/usd_eur.csv
    
Le CSV doit contenir les colonnes: Asset A, Asset B (ou similar) OU date,exchange_rate
"""

import sys
import json
import glob
import os
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from features import compute_features_from_close_series, WINDOW_MAX


def prepare_data(csv_path: str, asset_col: str = 'Asset A'):
    """
    Charge les donnÃ©es et prÃ©pare X (features) et y (labels).
    Supporte deux formats de CSV:
    1. Format "Asset A, Asset B" (phase1/phase3 avec index)
    2. Format Forex "date,exchange_rate" (currencies/)
    
    Args:
        csv_path: Chemin vers le fichier CSV
        asset_col: Nom de la colonne de prix Ã  utiliser (ou 'exchange_rate' pour Forex)
    
    Returns:
        X (array), y (array), feature_names (list)
    """
    print(f"Chargement des donnÃ©es depuis {csv_path}...")
    
    # Essayer de dÃ©tecter le format du fichier
    df_test = pd.read_csv(csv_path, nrows=5)
    
    if 'exchange_rate' in df_test.columns:
        # Format Forex: date,exchange_rate
        print("âœ“ Format Forex dÃ©tectÃ© (date,exchange_rate)")
        df = pd.read_csv(csv_path)
        asset_col = 'exchange_rate'
        print(f"Date range: {df['date'].iloc[0]} â†’ {df['date'].iloc[-1]}")
    elif 'Asset A' in df_test.columns or 'Asset B' in df_test.columns:
        # Format Asset A/B avec index
        print("âœ“ Format Asset A/B dÃ©tectÃ©")
        df = pd.read_csv(csv_path, index_col=0)
    else:
        # Essayer de charger avec index par dÃ©faut
        df = pd.read_csv(csv_path, index_col=0)
    
    if asset_col not in df.columns:
        raise ValueError(f"Colonne '{asset_col}' non trouvÃ©e. Colonnes disponibles: {df.columns.tolist()}")
    
    print(f"Nombre de lignes: {len(df)}")
    
    # CrÃ©er le label : future_return et y
    df['future_return'] = df[asset_col].shift(-1) / df[asset_col] - 1
    df['y'] = (df['future_return'] > 0).astype(int)
    
    # Supprimer les NaN
    df = df.dropna()
    print(f"Nombre de lignes aprÃ¨s nettoyage: {len(df)}")
    
    # Calculer les features pour chaque ligne
    closes = df[asset_col].tolist()
    X_list = []
    y_list = []
    
    print("Calcul des features...")
    for i in range(WINDOW_MAX, len(closes)):
        # Prendre la fenÃªtre de prix jusqu'Ã  i (inclus)
        window = closes[:i+1]
        
        # Calculer les features
        try:
            features = compute_features_from_close_series(window)
            X_list.append(features)
            # Le label correspond Ã  l'index i dans le DataFrame nettoyÃ©
            # Mais attention: aprÃ¨s dropna, les indices peuvent ne pas correspondre
            # On utilise iloc pour Ãªtre sÃ»r
            y_list.append(df.iloc[i]['y'])
        except Exception as e:
            print(f"Erreur Ã  l'index {i}: {e}")
            continue
    
    X = np.array(X_list)
    y = np.array(y_list)
    
    print(f"Shape de X: {X.shape}")
    print(f"Shape de y: {y.shape}")
    print(f"Distribution des labels - Hausse: {np.sum(y)}, Baisse: {len(y) - np.sum(y)}")
    
    feature_names = ['ret_1', 'ret_5', 'ret_10', 'vol_10', 'ma_ratio_5_20']
    
    return X, y, feature_names


def train_model(X, y):
    """
    EntraÃ®ne un modÃ¨le de rÃ©gression logistique avec split temporel.
    
    Args:
        X: Features
        y: Labels
    
    Returns:
        model: ModÃ¨le entraÃ®nÃ©
        X_train, X_test, y_train, y_test: DonnÃ©es de train/test
    """
    # Split temporel (important pour le trading)
    n = len(X)
    train_size = int(n * 0.7)
    
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    print(f"\nSplit temporel:")
    print(f"  Train: {len(X_train)} samples")
    print(f"  Test: {len(X_test)} samples")
    
    # EntraÃ®ner le modÃ¨le
    print("\nEntraÃ®nement du modÃ¨le...")
    model = LogisticRegression(max_iter=1000, random_state=42)
    model.fit(X_train, y_train)
    
    # Ã‰valuation
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    train_acc = accuracy_score(y_train, y_train_pred)
    test_acc = accuracy_score(y_test, y_test_pred)
    
    print(f"\nAccuracy Train: {train_acc:.4f}")
    print(f"Accuracy Test: {test_acc:.4f}")
    
    print("\nRapport de classification (Test):")
    print(classification_report(y_test, y_test_pred, target_names=['Baisse', 'Hausse']))
    
    return model, X_train, X_test, y_train, y_test


def export_model_weights(model, feature_names, output_path='forex_model_weights.json'):
    """
    Exporte les poids du modÃ¨le dans un fichier JSON.
    
    Args:
        model: ModÃ¨le entraÃ®nÃ©
        feature_names: Noms des features
        output_path: Chemin du fichier JSON de sortie
    """
    coef = model.coef_[0].tolist()
    intercept = float(model.intercept_[0])
    
    weights_dict = {
        'coef': coef,
        'intercept': intercept,
        'feature_names': feature_names,
        'n_features': len(coef)
    }
    
    with open(output_path, 'w') as f:
        json.dump(weights_dict, f, indent=2)
    
    print(f"\nModÃ¨le exportÃ© dans {output_path}")
    print(f"Nombre de features: {len(coef)}")
    print(f"Intercept: {intercept:.6f}")
    print("\nCoefficients:")
    for name, w in zip(feature_names, coef):
        print(f"  {name}: {w:.6f}")


def prepare_multiple_datasets(csv_paths: list) -> tuple:
    """
    Charge et combine plusieurs datasets pour l'entraÃ®nement.
    
    Args:
        csv_paths: Liste de chemins vers les fichiers CSV
    
    Returns:
        X_combined (array), y_combined (array), feature_names (list)
    """
    X_all = []
    y_all = []
    feature_names = None
    
    print(f"ğŸ“Š Chargement de {len(csv_paths)} dataset(s)...\n")
    
    for i, csv_path in enumerate(csv_paths, 1):
        try:
            print(f"[{i}/{len(csv_paths)}] {csv_path}")
            
            # DÃ©tecter le type de colonne
            if 'currencies' in csv_path or 'eur.csv' in csv_path.lower():
                asset_col = 'exchange_rate'
            else:
                asset_col = 'Asset A'
            
            # PrÃ©parer les donnÃ©es pour ce fichier
            X, y, feat_names = prepare_data(csv_path, asset_col)
            
            X_all.append(X)
            y_all.append(y)
            
            if feature_names is None:
                feature_names = feat_names
            
            print(f"    âœ“ {X.shape[0]} samples ajoutÃ©s\n")
            
        except Exception as e:
            print(f"    âš ï¸  Erreur lors du chargement: {e}\n")
            continue
    
    if len(X_all) == 0:
        raise ValueError("Aucun dataset n'a pu Ãªtre chargÃ©!")
    
    # Combiner tous les datasets
    X_combined = np.vstack(X_all)
    y_combined = np.concatenate(y_all)
    
    print(f"{'='*70}")
    print(f"ğŸ“ˆ DONNÃ‰ES COMBINÃ‰ES")
    print(f"{'='*70}")
    print(f"Total samples: {X_combined.shape[0]:,}")
    print(f"Total features: {X_combined.shape[1]}")
    print(f"Hausse: {np.sum(y_combined):,} ({np.sum(y_combined)/len(y_combined)*100:.1f}%)")
    print(f"Baisse: {len(y_combined) - np.sum(y_combined):,} ({(1-np.sum(y_combined)/len(y_combined))*100:.1f}%)")
    print(f"{'='*70}\n")
    
    return X_combined, y_combined, feature_names


def main():
    if len(sys.argv) < 2:
        print("Usage: python train_model.py <path_to_csv_or_directory> [path2] [path3] ...")
        print("\nExemples:")
        print("  # Un seul fichier")
        print("  python train_model.py data/asset_a_b_train.csv")
        print("  python train_model.py data/currencies/gbp_eur.csv")
        print()
        print("  # Plusieurs fichiers")
        print("  python train_model.py data/currencies/gbp_eur.csv data/currencies/usd_eur.csv")
        print()
        print("  # Un dossier entier (tous les .csv)")
        print("  python train_model.py data/currencies/")
        print()
        print("  # MÃ©lange fichiers et dossiers")
        print("  python train_model.py data/currencies/ data/asset_a_b_train.csv")
        sys.exit(1)
    
    # RÃ©cupÃ©rer tous les chemins de fichiers ou dossiers
    input_paths = sys.argv[1:]
    
    # RÃ©soudre les chemins : fichiers individuels ou tous les CSV d'un dossier
    csv_paths = []
    
    for path in input_paths:
        if os.path.isfile(path) and path.endswith('.csv'):
            # C'est un fichier CSV
            csv_paths.append(path)
        elif os.path.isdir(path):
            # C'est un dossier, prendre tous les fichiers .csv
            pattern = os.path.join(path, '*.csv')
            found_files = glob.glob(pattern)
            csv_paths.extend(found_files)
            print(f"ğŸ“ Dossier dÃ©tectÃ©: {path} ({len(found_files)} fichiers CSV trouvÃ©s)")
        elif '*' in path:
            # Pattern avec wildcard
            found_files = glob.glob(path)
            csv_paths.extend([f for f in found_files if f.endswith('.csv')])
        else:
            print(f"âš ï¸  IgnorÃ© (ni fichier CSV ni dossier): {path}")
    
    # Filtrer pour garder uniquement les fichiers CSV valides et uniques
    valid_paths = list(set([p for p in csv_paths if p.endswith('.csv') and os.path.isfile(p)]))
    
    if len(valid_paths) == 0:
        print("âŒ Aucun fichier CSV valide trouvÃ©!")
        sys.exit(1)
    
    # Trier par nom pour avoir un ordre prÃ©visible
    valid_paths.sort()
    
    print(f"\n{'='*70}")
    print(f"ğŸš€ ENTRAÃNEMENT DU MODÃˆLE DE TRADING")
    print(f"{'='*70}")
    print(f"Nombre de datasets: {len(valid_paths)}")
    print(f"{'='*70}\n")
    
    # PrÃ©parer les donnÃ©es (un ou plusieurs datasets)
    if len(valid_paths) == 1:
        # Un seul dataset
        csv_path = valid_paths[0]
        if 'currencies' in csv_path or 'eur.csv' in csv_path.lower():
            asset_col = 'exchange_rate'
        else:
            asset_col = 'Asset A'
        X, y, feature_names = prepare_data(csv_path, asset_col)
    else:
        # Plusieurs datasets
        X, y, feature_names = prepare_multiple_datasets(valid_paths)
    
    # EntraÃ®ner le modÃ¨le
    model, X_train, X_test, y_train, y_test = train_model(X, y)
    
    # Exporter les poids
    export_model_weights(model, feature_names)
    
    print("\nâœ… EntraÃ®nement terminÃ© avec succÃ¨s!")


if __name__ == '__main__':
    main()
